{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bbe1d2-81a1-424a-b920-87b0c3f4b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")\n",
    "from utils.utils import LocalPLM, LocalModelArguments\n",
    "from utils import preprocess as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "273b0963-b12a-4a8a-974a-a33fa1b34f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1314453ba344d6abd3d099edfd4b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/39132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dbb39f18a943538c778577224ecd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be6319b2fa249d192a3c74c68958139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45242b1f57ce4cad8aafebbebb34d6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, _ = pr.load_dataset(\"data_combined.csv\", \"content\", \"label\", ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12227389-f046-4bf8-a20c-ba34fb009580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a645d20d743e474ebf09f785a7de01aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"microsoft/Phi-4-mini-instruct\",\n",
    "    cuda_devices = \"0\",\n",
    "    use_4bit_quantization = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = \"float16\",\n",
    "    use_nested_quant = True,\n",
    "    use_reentrant = True\n",
    ")\n",
    "\n",
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c37b990-feba-4563-ba4c-2307af8d73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_LLM_PATH = \"models/Test\"\n",
    "\n",
    "LORA_RANK_DIMENSION = 6 # the rank of the adapter, the lower the fewer parameters you'll need to train. (smaller = more compression)\n",
    "LORA_ALPHA = 8 # this is the scaling factor for LoRA layers (higher = stronger adaptation)\n",
    "LORA_DROPOUT = 0.05 # dropout probability for LoRA layers (helps prevent overfitting)\n",
    "MAX_SEQ_LENGTH = 64\n",
    "EPOCHS=1\n",
    "LEARNING_RATE=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecd86cb9-18e2-480e-897e-029728ec5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_RANK_DIMENSION,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    bias=\"none\",\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d5bddac-833c-4ddf-a9b0-32c2aa22b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    \n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    packing=True,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optim='adamw_torch_fused',\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\", \n",
    "    \n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    output_dir=FINETUNED_LLM_PATH,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e98446-0bb9-461a-a917-ba5b7246d4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9d93e30fe249708475e16d243d627c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'fn_kwargs'={'tokenizer': GPT2TokenizerFast(name_or_path='microsoft/Phi-4-mini-instruct', vocab_size=200019, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t199999: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200018: AddedToken(\"<|endofprompt|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200019: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200020: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200021: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200022: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200023: AddedToken(\"<|tool|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200024: AddedToken(\"<|/tool|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200025: AddedToken(\"<|tool_call|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200026: AddedToken(\"<|/tool_call|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200027: AddedToken(\"<|tool_response|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200028: AddedToken(\"<|tag|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320f3ebe7238465f8fd9f71d05d94360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d82e54495de4e389b9588c0fbac8c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f6a77147104618b6edd180ac0da7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Packing train dataset:   0%|          | 0/3913 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='2170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  11/2170 03:57 < 15:49:26, 0.04 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer, history = model.finetune(\n",
    "    train_dataset=data,\n",
    "    lora_config=lora_config, sft_config=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d3b02-448c-4b6c-ba08-8696597c4bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
