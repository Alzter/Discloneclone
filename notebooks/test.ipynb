{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a01718-3816-4e17-a9c1-fcee55d80229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "from utils import LocalPLM, LocalModelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7fc57-9f5b-4111-85c2-a98ccf2a8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"microsoft/Phi-4-mini-instruct\",\n",
    "    cuda_devices = \"0\",\n",
    "    use_4bit_quantization = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = \"float16\",\n",
    "    use_nested_quant = True,\n",
    "    use_reentrant = True\n",
    ")\n",
    "\n",
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5618f3-9450-4995-8713-c47e13282b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../discord-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8d678-b76c-4ea6-b13f-ba0251746d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def get_chat(user : str, path : str):\n",
    "    user = \"ThisGreenDingo\"\n",
    "    conversation = path + \"/Direct Messages - \" + user + \" [*.csv\"\n",
    "    conversation = glob.glob(conversation)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f7014-954a-4837-b1c3-d81b15871c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def is_new_conversation(delay : timedelta, max_delay_mins : int = 50):\n",
    "    max_delay = timedelta(minutes = max_delay_mins)\n",
    "    return delay > max_delay\n",
    "    \n",
    "def read_conversation(path : str) -> pd.DataFrame:\n",
    "    def parse_time_str(time : str) -> datetime:\n",
    "        return datetime.strptime(time,'%Y-%m-%dT%H:%M:%S.%f0%z')\n",
    "        \n",
    "    c = pd.read_csv(path)\n",
    "    c[\"Date\"] = c[\"Date\"].map(parse_time_str)\n",
    "    c[\"Delay\"] = c[\"Date\"] - c[\"Date\"].shift(1)\n",
    "    c[\"Delay\"] = c[\"Delay\"].fillna( timedelta(seconds=0) )\n",
    "    c[\"Start\"] = c[\"Delay\"].map(is_new_conversation)\n",
    "    c.loc[0, \"Start\"] = True\n",
    "    return c\n",
    "\n",
    "def get_chat(user : str, path : str) -> pd.DataFrame:\n",
    "    path = path + \"/Direct Messages - \" + user + \" [*.csv\"\n",
    "    conversation = glob.glob(path)\n",
    "\n",
    "    if conversation:\n",
    "        return read_conversation(conversation[0])\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No conversation(s) found at path {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a7045-cf17-47a6-b531-64edf3f466dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_indices(messages : pd.DataFrame) -> list[int]:\n",
    "    start_indices = messages[messages[\"Start\"] == True].index\n",
    "\n",
    "    indices = []\n",
    "    for i in range(len(start_indices)):\n",
    "        if i >= len(start_indices) - 1: continue\n",
    "        indices.append(\n",
    "            list(range(start_indices[i], start_indices[i+1]))\n",
    "        )\n",
    "    return indices\n",
    "\n",
    "def split_by_conversations(messages : pd.DataFrame, min_conv_length : int = 5, max_conv_length : int = 30) -> list[pd.DataFrame]:\n",
    "    conversation_indices = get_conversation_indices(messages)\n",
    "    \n",
    "    conversations = []\n",
    "    for indices in conversation_indices:\n",
    "\n",
    "        if len(indices) < min_conv_length: continue\n",
    "\n",
    "        # Slice indices so they don't exceed max_conv_length\n",
    "        indices = [indices[i:i + max_conv_length] for i in range(0, len(indices), max_conv_length)]\n",
    "\n",
    "        for sub_indices in indices:\n",
    "            conversations.append(messages.iloc[sub_indices])\n",
    "\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c40a9-fac2-4e2f-b75b-9635d9d8c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_chat(\"Grumpy Koala\", DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef4366-e6b2-4e2f-9391-e4d86e493ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = split_by_conversations(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5f702-2620-41b4-8d27-f4ce6bbb3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea698fc-5df9-42c4-82d3-99d4757e6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(messages : pd.DataFrame) -> str:\n",
    "    messages = messages\n",
    "\n",
    "    end_time = messages.iloc[-1].Date\n",
    "    \n",
    "    string = \"Conversation history between \" + \", \".join(messages.Author.unique())\n",
    "    string += \"\\n\" + end_time.strftime(\"%y/%m/%d, %H:%M:%S\") + \"\\n\\n\"\n",
    "    for i, message in messages.iterrows():\n",
    "        string += f\"{message.Author} {message.Date.strftime(\"%H:%M:%S\")}\"\n",
    "        string += f\"\\n{message.Content}\\n\\n\"\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f645ce-adeb-492e-bc15-19325b1e6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(messages : pd.DataFrame, prompt : str, context : str | None = None) -> str:\n",
    "    messages = to_string(messages)\n",
    "\n",
    "    if context: prompt += f\"\\nContext: {context}.\\nAnswer concisely.\"\n",
    "\n",
    "    prompt = [{\"role\":\"system\",\"content\":prompt}]\n",
    "    \n",
    "    prompt.append({\"role\":\"user\",\"content\":messages})\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bd2a0-fdec-4713-a4d7-de80791e4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def understand_conversation(messages : pd.DataFrame, context : str | None = None) -> dict:\n",
    "    relationship_prompt= \"Read the following conversation history and tell me what you think the relationship is between the users. Answer succinctly.\"\n",
    "    relationship_prompt = gen_prompt(messages, relationship_prompt, context=context)\n",
    "    relationship = model.generate(relationship_prompt,temperature=1,max_new_tokens = 128).text\n",
    "    \n",
    "    topic_prompt=\"Read the following conversation history and tell me what was discussed. Answer succinctly.\"\n",
    "    topic_prompt = gen_prompt(messages, topic_prompt, context=relationship)\n",
    "    topic = model.generate(topic_prompt,temperature=1,max_new_tokens = 128).text\n",
    "\n",
    "    return {\"relationship\":relationship,\"topic\":topic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0796fb9-62d9-4642-984b-fcfa969259a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def understand_conversations(conversations : list[pd.DataFrame]) -> pd.DataFrame:\n",
    "    # We will generate the context for each conversation\n",
    "    contexts = []\n",
    "\n",
    "    # Each conversation is given the context of the previous\n",
    "    # conversation to recursively build meaning. To start with\n",
    "    # we have zero previous context, so set context_str to None.\n",
    "    context_str = None\n",
    "\n",
    "    # Parse the meaning of each conversation sequentially\n",
    "    for conversation in tqdm(conversations, \"Understanding conversations\"):\n",
    "        context = understand_conversation(conversation, context=context_str)\n",
    "        contexts.append(context)\n",
    "\n",
    "        # Give the next conversation the summarised topic of this\n",
    "        # conversation for added context to improve meaning extraction\n",
    "        context_str = f\"Previous discussion: {context[\"topic\"]}\"\n",
    "    \n",
    "    # Restructure contexts from list of dicts -> dict of lists\n",
    "    contexts = pd.DataFrame(contexts).to_dict(orient='list')\n",
    "\n",
    "    return pd.DataFrame(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ef98c-8e19-4fd1-9e0a-0cb54c84ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = understand_conversations(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb012c7-6cf1-4818-98a7-5922617bda79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
